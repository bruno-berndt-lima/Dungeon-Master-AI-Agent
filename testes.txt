import logging
from src.models.llm import create_llm
from src.pipelines.generator import create_rag_chain
from src.pipelines.grader import create_retrieval_grader
from src.pipelines.rewriter import create_question_rewriter
from src.data.loader import load_documents
from src.data.processing import split_documents
from src.data.vectorstore import get_vectorstore
from src.config import DOCUMENT_PATHS

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def initialize_pipeline():
    """Initialize all pipeline components."""
    # Initialize LLM
    llm = create_llm()
    
    # Load and process documents
    docs = load_documents(DOCUMENT_PATHS)
    doc_splits = split_documents(docs)
    vectorstore = get_vectorstore(doc_splits)
    retriever = vectorstore.as_retriever(search_type="similarity", k=3)
    logger.info("ChromaDB and retriever setup complete.")

    # Initialize chains
    retrieval_grader = create_retrieval_grader(llm)
    rag_chain = create_rag_chain(llm)
    question_rewriter = create_question_rewriter(llm)
    
    return retriever, retrieval_grader, rag_chain, question_rewriter

def process_query(query: str, retriever, retrieval_grader, rag_chain, question_rewriter):
    """Process a user query through the RAG pipeline."""
    logger.info(f"Processing query: {query}")
    
    # 1. Rewrite the question
    improved_query = question_rewriter.invoke({"question": query})
    logger.info(f"Improved query: {improved_query}")
    
    # 2. Retrieve relevant documents
    retrieved_docs = retriever.invoke(improved_query)
    
    # 3. Grade relevance of documents
    graded_docs = []
    for doc in retrieved_docs:
        grade = retrieval_grader.invoke({
            "question": improved_query,
            "document": doc.page_content
        })
        if grade.binary_score.lower() == 'yes':
            graded_docs.append(doc)
    
    # 4. Generate response using filtered documents
    if graded_docs:
        response = rag_chain.invoke({
            "context": graded_docs,
            "question": improved_query
        })
        return response
    else:
        return "I couldn't find relevant information to answer your question."

def main():
    # Initialize pipeline components once
    print("Initializing D&D adventure...")
    pipeline_components = initialize_pipeline()
    print("\nD&D Assistant ready! Type 'quit' or 'exit' to end the session.")
    
    while True:
        # Get user input
        query = input("\nüé≤ Ask a D&D question: ").strip()
        
        # Check for exit command
        if query.lower() in ['quit', 'exit']:
            print("Goodbye!")
            break
        
        # Skip empty queries
        if not query:
            continue
            
        try:
            # Process query and print response
            result = process_query(query, *pipeline_components)
            print("\nüìù Response:", result)
            
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            print("\n‚ùå Sorry, there was an error processing your question. Please try again.")

if __name__ == "__main__":
    main()